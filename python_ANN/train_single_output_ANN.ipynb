{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "train_single_output_ANN.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mbLsjPUk3oIb",
        "colab_type": "text"
      },
      "source": [
        "## Training a Single-Output ANN from scratch\n",
        "\n",
        "Note: this script trains only one ANN for the station selected by user. Please set 'output_stations' to different stations for training multiple ANNs."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YHPnGTMf95oI",
        "colab_type": "code",
        "outputId": "724faff1-89f7-4955-9130-be32afc80ba5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "######## User Settings ########\n",
        "\n",
        "#### 1. Select parameters to be used ####\n",
        "input_var = ['SAC','Exp','SJR','DICU','Vern','SF_Tide','DXC']\n",
        "#### 2. Select stations to be predicted ####\n",
        "# choose ONE of 'Emmaton','Jersey Point','Collinsville','Rock Slough'\n",
        "output_stations=['Rock Slough']\n",
        "#### 3. Specify directory to excel dataset and the helper script (folder name only) ####\n",
        "google_drive_dir = 'python_ANN'\n",
        "\n",
        "###### User Settings Finished ######\n",
        "\n",
        "from google.colab import drive\n",
        "import os\n",
        "# Mount Google drive\n",
        "data_in_google_drive = True\n",
        "\n",
        "if data_in_google_drive:\n",
        "    drive.mount('/content/drive',force_remount=True)\n",
        "    xl_path = os.path.join('/content/drive','My Drive',google_drive_dir,\"ANN_data.xlsx\")\n",
        "    %tensorflow_version 1.x\n",
        "else:\n",
        "    xl_path = \"ANN_data.xlsx\""
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n",
            "TensorFlow 1.x selected.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t6Wd7z3l996j",
        "colab_type": "text"
      },
      "source": [
        "##1. Read data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D6GxpZSUj0dF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# import helper functions\n",
        "import sys\n",
        "!export PYTHONPATH=\"\"\n",
        "sys.path.append(os.path.join('/content/drive','My Drive',google_drive_dir))\n",
        "from ann_helper import read_data,normalize_in,writeF90,initnw,show_eval"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n6348s2lzcfC",
        "colab_type": "code",
        "outputId": "8da2addb-5f3d-4894-8c7a-8c5bf33f69ee",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "source": [
        "import tensorflow as tf\n",
        "import math\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "import time\n",
        "# from sklearn.utils import shuffle\n",
        "from scipy import stats\n",
        "\n",
        "test_mode = False\n",
        "\n",
        "locs = {'Emmaton':0,'Jersey Point':1,'Collinsville':2,'Rock Slough':3}\n",
        "abbrev_map = {'rock slough':'ORRSL','rockslough':'ORRSL',\n",
        "            'emmaton':'EMM','jersey point':'JP','jerseypoint':'JP',\n",
        "            'antioch':'antioch','collinsville':'CO',\n",
        "            'mallard':'Mallard','mallard island':'Mallard',\n",
        "            'los vaqueros':'LosVaqueros','losvaqueros':'LosVaqueros',\n",
        "            'martinez':'MTZ',\n",
        "            'middle river':'MidR_intake','MiddleRiver':'MidR_intake',\n",
        "            'victoria cannal':'Victoria_intake','Vict Intake':'Victoria_intake',\n",
        "            'cvp intake':'CVP_intake','clfct forebay':'CCFB',\n",
        "            'clfct forebay intake':'CCFB_intake','x2':'X2'};\n",
        "\n",
        "output_stations = sorted(output_stations,key=lambda x: locs[x])\n",
        "\n",
        "device_name = tf.test.gpu_device_name()\n",
        "if device_name != '/device:GPU:0':\n",
        "    raise SystemError('GPU device not found')\n",
        "#   print('xxxxxxxxxxxxxx Using CPU xxxxxxxxxxxxxx')\n",
        "else:\n",
        "    print('Found GPU at: {}'.format(device_name))\n",
        "\n",
        "\n",
        "input_shape = (1,17*len(input_var))\n",
        "output_shape = 1\n",
        "nn_shape = [17*len(input_var),8,2,1] # number of neurons in each layer\n",
        "on_server = True\n",
        "\n",
        "# LM optimizer settings\n",
        "max_fail = 3\n",
        "epochs = 10\n",
        "init_mu = .05\n",
        "mu_max = 1e10\n",
        "target_mse = 0.\n",
        "\n",
        "# adam optimizer settings\n",
        "adam_epochs = 100\n",
        "batch_size = 32\n",
        "\n",
        "\n",
        "if test_mode or device_name != '/device:GPU:0':\n",
        "    epochs = 5\n",
        "else:\n",
        "    epochs = 100\n",
        "\n",
        "train_loc = locs[output_stations[0]]\n",
        "ann_name = abbrev_map[output_stations[0].lower()]\n",
        "start = time.time()\n",
        "\n",
        "# read data from excel\n",
        "x_data,y_data = read_data(xl_path,input_var,output_stations)\n",
        "end = time.time()\n",
        "print(\"loading data in %.2f seconds\" % (end-start) )\n",
        "    \n",
        "# normalize data to 0.1 ~ 0.9\n",
        "[x_norm,x_slope,x_bias] = normalize_in(x_data)\n",
        "[y_norm,y_slope,y_bias] = normalize_in(y_data)\n",
        "\n",
        "# split 80% for training, 20% for testing\n",
        "x_train_ori, x_test_ori, y_train0, y_test0 = train_test_split(x_norm,\n",
        "                                                              y_norm,\n",
        "                                                              test_size=0.2,\n",
        "                                                              random_state = 0)\n",
        "\n",
        "if test_mode:\n",
        "    x_train_ori = x_train_ori[:100]\n",
        "    x_test_ori = x_test_ori[:100]\n",
        "    y_train0 = y_train0[:100]\n",
        "    y_test0 = y_test0[:100]\n",
        "train_err = []\n",
        "test_err = []\n",
        "train_shape = len(x_train_ori)\n"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found GPU at: /device:GPU:0\n",
            "Disgarding last 1 row(s) of data in output set...\n",
            "loading data in 28.19 seconds\n",
            "loading data in 28.22 seconds\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lZNeDaHG0fyp",
        "colab_type": "code",
        "outputId": "64de8cfc-d41a-4ba5-9b5c-d50ee5b7b08a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# build artificial neural network\n",
        "tf.compat.v1.reset_default_graph()\n",
        "tf.compat.v1.set_random_seed(1)\n",
        "\n",
        "x = tf.compat.v1.placeholder(tf.float32, [None, 17*len(input_var)], name='InputData')\n",
        "y = tf.compat.v1.placeholder(tf.float32, [None, 1], name='LabelData')\n",
        "\n",
        "init_val = initnw(list(zip(*(nn_shape[i:] for i in range(2)))),x_train_ori)\n",
        "\n",
        "W1 = tf.Variable(initial_value=init_val[0][0], name='w1',dtype='float32')\n",
        "b1 = tf.Variable(initial_value=init_val[0][1], name='b1',dtype='float32')\n",
        "W2 = tf.Variable(initial_value=init_val[1][0], name='w2',dtype='float32')\n",
        "b2 = tf.Variable(initial_value=init_val[1][1], name='b2',dtype='float32')\n",
        "W3 = tf.Variable(initial_value=init_val[2][0], name='w3',dtype='float32')\n",
        "b3 = tf.Variable(initial_value=init_val[2][1], name='b3',dtype='float32')\n",
        "\n",
        "with tf.compat.v1.name_scope('layer1'):\n",
        "    first_out = tf.sigmoid(tf.add(tf.matmul(x,W1),b1))\n",
        "with tf.compat.v1.name_scope('layer2'):\n",
        "    second_out = tf.sigmoid(tf.add(tf.matmul(first_out,W2),b2))\n",
        "# with tf.name_scope('layer3'):\n",
        "#     third_out = tf.sigmoid(tf.add(tf.matmul(second_out,W3),b3))\n",
        "with tf.compat.v1.name_scope('layer3'):\n",
        "    pred = tf.matmul(second_out, W3) + b3\n",
        "\n",
        "# residuals\n",
        "r = tf.subtract(pred,y)\n",
        "# loss function must be mse or sse for LM\n",
        "cost = tf.reduce_mean(input_tensor=tf.square(tf.subtract(pred,y)))\n",
        "\n",
        "\n",
        "# For adam optimizer:\n",
        "global_step = tf.Variable(0, trainable=False)\n",
        "initial_lr = 1e-2\n",
        "learning_rate = tf.compat.v1.train.exponential_decay(initial_lr, global_step,\n",
        "                                       40, 0.999, staircase=True)\n",
        "# Adam optimizer\n",
        "with tf.compat.v1.name_scope('train_op'):\n",
        "    adam_opt = tf.compat.v1.train.AdamOptimizer(learning_rate=learning_rate).minimize(cost,global_step = global_step)\n",
        "\n",
        "# LM optimizer\n",
        "with tf.compat.v1.name_scope('train_op'):\n",
        "    opt = tf.compat.v1.train.GradientDescentOptimizer(learning_rate=1)\n",
        "\n",
        "with tf.compat.v1.name_scope('Accuracy'):\n",
        "    # Accuracy\n",
        "    acc = tf.reduce_mean(input_tensor=tf.square(tf.subtract(pred,y)))\n",
        "\n",
        "# Initialize the variables (i.e. assign their default value)\n",
        "init = tf.compat.v1.global_variables_initializer()\n",
        "\n",
        "\n",
        "# LM algorithm\n",
        "def jacobian(y, x):\n",
        "    loop_vars = [\n",
        "        tf.constant(0, tf.int32),\n",
        "        tf.TensorArray(tf.float32, size=train_shape),\n",
        "    ]\n",
        "\n",
        "    _, jacobian = tf.while_loop(\n",
        "        cond=lambda i, _: i < train_shape,\n",
        "        body=lambda i, res: (i+1, res.write(i, tf.reshape(tf.gradients(ys=y[i], xs=x), (-1,)))),\n",
        "        loop_vars=loop_vars)\n",
        "    return jacobian.stack()\n",
        "\n",
        "\n",
        "r_flat = tf.expand_dims(tf.reshape(r,[-1]),1)\n",
        "parms = [W1, b1, W2, b2, W3, b3]\n",
        "parms_sizes = [tf.size(input=p) for p in parms]\n",
        "j = tf.concat([jacobian(r_flat, p) for p in parms], 1)\n",
        "jT = tf.transpose(a=j)\n",
        "hess_approx = tf.matmul(jT, j)\n",
        "grad_approx = tf.matmul(jT, r_flat)\n",
        "\n",
        "mu = tf.compat.v1.placeholder(tf.float32, shape=[])\n",
        "\n",
        "store = [tf.Variable(tf.zeros(p.shape, dtype=tf.float32)) for p in parms]\n",
        "save_parms = [tf.compat.v1.assign(s, p) for s, p in zip(store, parms)]\n",
        "restore_parms = [tf.compat.v1.assign(p, s) for s, p in zip(store, parms)]\n",
        "\n",
        "wb_flat = tf.concat([tf.reshape(p,[-1,1]) for p in parms],axis=0)\n",
        "n = tf.add_n(parms_sizes)\n",
        "I = tf.eye(n, dtype=tf.float32)\n",
        "w_2 = tf.reduce_sum(input_tensor=tf.square(wb_flat))\n",
        "\n",
        "\n",
        "sess = tf.compat.v1.Session()\n",
        "sess.run(init)\n",
        "print(\"Number of trainable parameters: %d\" % sess.run(n))\n",
        "\n",
        "\n",
        "#  lm algorithm\n",
        "dp_flat = tf.matmul(tf.linalg.inv(hess_approx + tf.multiply(mu, I)), grad_approx)\n",
        "dps = tf.split(dp_flat, parms_sizes, 0)\n",
        "\n",
        "for i in range(len(dps)):\n",
        "    dps[i] = tf.reshape(dps[i], parms[i].shape)\n",
        "lm = opt.apply_gradients(zip(dps, parms))\n"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of trainable parameters: 981\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tVgyRTmYsLR4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "saver = tf.compat.v1.train.Saver({'W1':W1,'b1':b1,'W2':W2,'b2':b2,'W3':W3,'b3':b3})"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Dy1XKPUeKd10",
        "colab_type": "code",
        "outputId": "a8b2ed85-135b-47be-d279-b1d8776482ad",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "# Adam optimizer training\n",
        "\n",
        "\n",
        "# Feed batch data\n",
        "def get_batch(inputX, inputY, batch_size):\n",
        "    duration = len(inputX)\n",
        "    for i in range(0,duration//batch_size):\n",
        "        idx = i*batch_size\n",
        "        yield inputX[idx:idx+batch_size], inputY[idx:idx+batch_size]\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# Start training\n",
        "\n",
        "start = time.time()\n",
        "with sess.as_default():\n",
        "    with sess.graph.as_default():\n",
        "        cost_list = []\n",
        "        lr_list = []\n",
        "        # Run the initializer\n",
        "        sess.run(init)\n",
        "\n",
        "        # Training cycle\n",
        "        total_batch = train_shape//batch_size\n",
        "        for epoch in range(adam_epochs):\n",
        "            avg_cost = 0.\n",
        "            ii = 0\n",
        "            # Loop over all batches\n",
        "            for batch_xs, batch_ys in get_batch(x_train_ori, y_train0,batch_size):\n",
        "                ii = ii +1\n",
        "                # Run optimization op (backprop), cost op (to get loss value)\n",
        "                # and summary nodes\n",
        "                _, c = sess.run([adam_opt, cost],\n",
        "                                 feed_dict={x: batch_xs, y: batch_ys})\n",
        "                # Write logs at every iteration\n",
        "                # Compute average loss\n",
        "                avg_cost += c / total_batch\n",
        "            lr = learning_rate.eval()\n",
        "            cost_list.append(avg_cost)\n",
        "            lr_list.append(lr)\n",
        "            # Display logs per epoch step\n",
        "            print(\"Epoch:\", '%04d' % (epoch+1), \"cost=\", \"{:.9f}\".format(avg_cost),\n",
        "                  \"lr = \",\"{:.10f}\".format(lr))\n",
        "\n",
        "    print(\"Optimization Finished!\")\n",
        "\n",
        "    # Test model\n",
        "    # Calculate accuracy\n",
        "    print(\"Train Error:\", acc.eval({x: x_train_ori, y: y_train0}))\n",
        "    print(\"Test Error:\", acc.eval({x: x_test_ori, y: y_test0}))\n",
        "    y_test_ = sess.run(pred,feed_dict={x:x_test_ori})\n",
        "    print(\"Test MSE:\", np.mean(np.square((y_test_-y_test0)/y_slope)))\n",
        "    print(\"Test MAPE:\", np.mean(np.abs(y_test_-y_test0)/y_test0))\n"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch: 0001 cost= 0.038433652 lr =  0.0099999998\n",
            "Epoch: 0002 cost= 0.021106885 lr =  0.0099999998\n",
            "Epoch: 0003 cost= 0.022818989 lr =  0.0099999998\n",
            "Epoch: 0004 cost= 0.024256334 lr =  0.0099999998\n",
            "Epoch: 0005 cost= 0.022165340 lr =  0.0099999998\n",
            "Epoch: 0006 cost= 0.020156798 lr =  0.0099999998\n",
            "Epoch: 0007 cost= 0.019860800 lr =  0.0099999998\n",
            "Epoch: 0008 cost= 0.020131062 lr =  0.0099999998\n",
            "Epoch: 0009 cost= 0.019619025 lr =  0.0099999998\n",
            "Epoch: 0010 cost= 0.018512510 lr =  0.0099999998\n",
            "Epoch: 0011 cost= 0.017659117 lr =  0.0099999998\n",
            "Epoch: 0012 cost= 0.017228286 lr =  0.0099999998\n",
            "Epoch: 0013 cost= 0.016729049 lr =  0.0099999998\n",
            "Epoch: 0014 cost= 0.015825193 lr =  0.0099899992\n",
            "Epoch: 0015 cost= 0.014643857 lr =  0.0099899992\n",
            "Epoch: 0016 cost= 0.013410373 lr =  0.0099899992\n",
            "Epoch: 0017 cost= 0.012122099 lr =  0.0099899992\n",
            "Epoch: 0018 cost= 0.010608563 lr =  0.0099899992\n",
            "Epoch: 0019 cost= 0.009184576 lr =  0.0099899992\n",
            "Epoch: 0020 cost= 0.008204112 lr =  0.0099899992\n",
            "Epoch: 0021 cost= 0.007793193 lr =  0.0099899992\n",
            "Epoch: 0022 cost= 0.007487265 lr =  0.0099899992\n",
            "Epoch: 0023 cost= 0.007198838 lr =  0.0099899992\n",
            "Epoch: 0024 cost= 0.006853992 lr =  0.0099899992\n",
            "Epoch: 0025 cost= 0.006498046 lr =  0.0099899992\n",
            "Epoch: 0026 cost= 0.006148303 lr =  0.0099899992\n",
            "Epoch: 0027 cost= 0.005845694 lr =  0.0099800099\n",
            "Epoch: 0028 cost= 0.005610488 lr =  0.0099800099\n",
            "Epoch: 0029 cost= 0.005433601 lr =  0.0099800099\n",
            "Epoch: 0030 cost= 0.005279516 lr =  0.0099800099\n",
            "Epoch: 0031 cost= 0.005117232 lr =  0.0099800099\n",
            "Epoch: 0032 cost= 0.004948792 lr =  0.0099800099\n",
            "Epoch: 0033 cost= 0.004793434 lr =  0.0099800099\n",
            "Epoch: 0034 cost= 0.004661487 lr =  0.0099800099\n",
            "Epoch: 0035 cost= 0.004547470 lr =  0.0099800099\n",
            "Epoch: 0036 cost= 0.004439127 lr =  0.0099800099\n",
            "Epoch: 0037 cost= 0.004330114 lr =  0.0099800099\n",
            "Epoch: 0038 cost= 0.004225003 lr =  0.0099800099\n",
            "Epoch: 0039 cost= 0.004127643 lr =  0.0099800099\n",
            "Epoch: 0040 cost= 0.004035934 lr =  0.0099700298\n",
            "Epoch: 0041 cost= 0.003946371 lr =  0.0099700298\n",
            "Epoch: 0042 cost= 0.003860013 lr =  0.0099700298\n",
            "Epoch: 0043 cost= 0.003778376 lr =  0.0099700298\n",
            "Epoch: 0044 cost= 0.003700743 lr =  0.0099700298\n",
            "Epoch: 0045 cost= 0.003625348 lr =  0.0099700298\n",
            "Epoch: 0046 cost= 0.003552507 lr =  0.0099700298\n",
            "Epoch: 0047 cost= 0.003483104 lr =  0.0099700298\n",
            "Epoch: 0048 cost= 0.003416402 lr =  0.0099700298\n",
            "Epoch: 0049 cost= 0.003351154 lr =  0.0099700298\n",
            "Epoch: 0050 cost= 0.003287710 lr =  0.0099700298\n",
            "Epoch: 0051 cost= 0.003226912 lr =  0.0099700298\n",
            "Epoch: 0052 cost= 0.003168434 lr =  0.0099700298\n",
            "Epoch: 0053 cost= 0.003111481 lr =  0.0099700298\n",
            "Epoch: 0054 cost= 0.003056137 lr =  0.0099600600\n",
            "Epoch: 0055 cost= 0.003003019 lr =  0.0099600600\n",
            "Epoch: 0056 cost= 0.002951790 lr =  0.0099600600\n",
            "Epoch: 0057 cost= 0.002901920 lr =  0.0099600600\n",
            "Epoch: 0058 cost= 0.002853441 lr =  0.0099600600\n",
            "Epoch: 0059 cost= 0.002806594 lr =  0.0099600600\n",
            "Epoch: 0060 cost= 0.002761244 lr =  0.0099600600\n",
            "Epoch: 0061 cost= 0.002717139 lr =  0.0099600600\n",
            "Epoch: 0062 cost= 0.002674323 lr =  0.0099600600\n",
            "Epoch: 0063 cost= 0.002632921 lr =  0.0099600600\n",
            "Epoch: 0064 cost= 0.002592815 lr =  0.0099600600\n",
            "Epoch: 0065 cost= 0.002553831 lr =  0.0099600600\n",
            "Epoch: 0066 cost= 0.002515970 lr =  0.0099600600\n",
            "Epoch: 0067 cost= 0.002479259 lr =  0.0099500995\n",
            "Epoch: 0068 cost= 0.002443537 lr =  0.0099500995\n",
            "Epoch: 0069 cost= 0.002408863 lr =  0.0099500995\n",
            "Epoch: 0070 cost= 0.002375128 lr =  0.0099500995\n",
            "Epoch: 0071 cost= 0.002342313 lr =  0.0099500995\n",
            "Epoch: 0072 cost= 0.002310366 lr =  0.0099500995\n",
            "Epoch: 0073 cost= 0.002279230 lr =  0.0099500995\n",
            "Epoch: 0074 cost= 0.002248872 lr =  0.0099500995\n",
            "Epoch: 0075 cost= 0.002219259 lr =  0.0099500995\n",
            "Epoch: 0076 cost= 0.002190340 lr =  0.0099500995\n",
            "Epoch: 0077 cost= 0.002162071 lr =  0.0099500995\n",
            "Epoch: 0078 cost= 0.002134422 lr =  0.0099500995\n",
            "Epoch: 0079 cost= 0.002107361 lr =  0.0099500995\n",
            "Epoch: 0080 cost= 0.002080853 lr =  0.0099401502\n",
            "Epoch: 0081 cost= 0.002054816 lr =  0.0099401502\n",
            "Epoch: 0082 cost= 0.002029353 lr =  0.0099401502\n",
            "Epoch: 0083 cost= 0.002004352 lr =  0.0099401502\n",
            "Epoch: 0084 cost= 0.001979787 lr =  0.0099401502\n",
            "Epoch: 0085 cost= 0.001955636 lr =  0.0099401502\n",
            "Epoch: 0086 cost= 0.001931875 lr =  0.0099401502\n",
            "Epoch: 0087 cost= 0.001908481 lr =  0.0099401502\n",
            "Epoch: 0088 cost= 0.001885434 lr =  0.0099401502\n",
            "Epoch: 0089 cost= 0.001862718 lr =  0.0099401502\n",
            "Epoch: 0090 cost= 0.001840315 lr =  0.0099401502\n",
            "Epoch: 0091 cost= 0.001818209 lr =  0.0099401502\n",
            "Epoch: 0092 cost= 0.001796388 lr =  0.0099401502\n",
            "Epoch: 0093 cost= 0.001774840 lr =  0.0099401502\n",
            "Epoch: 0094 cost= 0.001753512 lr =  0.0099302102\n",
            "Epoch: 0095 cost= 0.001732497 lr =  0.0099302102\n",
            "Epoch: 0096 cost= 0.001711710 lr =  0.0099302102\n",
            "Epoch: 0097 cost= 0.001691169 lr =  0.0099302102\n",
            "Epoch: 0098 cost= 0.001670864 lr =  0.0099302102\n",
            "Epoch: 0099 cost= 0.001650771 lr =  0.0099302102\n",
            "Epoch: 0100 cost= 0.001630889 lr =  0.0099302102\n",
            "Optimization Finished!\n",
            "Train Error: 0.0015861286\n",
            "Test Error: 0.0044362084\n",
            "Test MSE: 24113.105\n",
            "Test MAPE: 0.24637264\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sw49GOpORTqm",
        "colab_type": "code",
        "outputId": "135ebd9a-ae49-4b77-b66c-3342a84633bd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "with sess.as_default():\n",
        "    with sess.graph.as_default():\n",
        "        print(\"Train Error before LM:\", acc.eval({x: x_train_ori, y: y_train0}))"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train Error before LM: 0.0015861286\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-FrIJ-IAfF9A",
        "colab_type": "code",
        "outputId": "4e024be1-b5f5-4031-81da-f4bdf0c06c97",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 551
        }
      },
      "source": [
        "\n",
        "feed_dict = {x: x_train_ori,\n",
        "             y: y_train0}\n",
        "feed_dict[mu] = init_mu\n",
        "\n",
        "# construct so-called feed dictionary to map placeholders to actual values\n",
        "\n",
        "validation_feed_dict = {x: x_test_ori,\n",
        "                        y: y_test0}\n",
        "\n",
        "train_break = False\n",
        "\n",
        "current_loss = sess.run(cost,{x: x_train_ori,y: y_train0})\n",
        "\n",
        "\n",
        "# Start training\n",
        "start = time.time()\n",
        "if not os.path.exists(os.path.join('/content/drive',\n",
        "                                   'My Drive',\n",
        "                                   google_drive_dir,\n",
        "                                   \"models\",\n",
        "                                   abbrev_map[output_stations[0].lower()])):\n",
        "    os.makedirs(os.path.join('/content/drive',\n",
        "                                   'My Drive',\n",
        "                                   google_drive_dir,\n",
        "                                   \"models\",\n",
        "                                   abbrev_map[output_stations[0].lower()]))\n",
        "\n",
        "with sess.as_default():\n",
        "    with sess.graph.as_default():\n",
        "        epoch = 1\n",
        "        fail_step = 0\n",
        "        # Training cycle\n",
        "        while epoch < epochs and current_loss > target_mse:\n",
        "            if not(epoch%2) or epoch == 1:\n",
        "                val_loss = sess.run(cost, validation_feed_dict)\n",
        "                print('epoch: %3d , mu: %.5e, train loss: %.10f, val loss: %.10f'%(epoch,feed_dict[mu],current_loss,val_loss))\n",
        "            sess.run(save_parms)\n",
        "            while True:\n",
        "                start_step = time.time()\n",
        "                sess.run(lm, feed_dict)\n",
        "                new_loss = sess.run(cost,feed_dict)\n",
        "                # print('One update ended in %d seconds' % (time.time()-start_step))\n",
        "                if new_loss > current_loss:\n",
        "                    fail_step += 1\n",
        "                    feed_dict[mu] *= 10\n",
        "                    if feed_dict[mu] > mu_max or fail_step > max_fail:\n",
        "                        train_break = True\n",
        "                        break\n",
        "                    sess.run(restore_parms)\n",
        "                else:\n",
        "                    print(\"mu: %.5e, new loss: %.5f, previous loss: %.5f\"%(feed_dict[mu],new_loss,current_loss))\n",
        "                    fail_step = 0\n",
        "                    feed_dict[mu] /= 10\n",
        "                    feed_dict[mu] = max(1e-20,feed_dict[mu])\n",
        "                    current_loss = new_loss\n",
        "                    break\n",
        "            if train_break:\n",
        "                print('Failed for %d step(s), current mu = %.5e, stop training' % (fail_step,feed_dict[mu]))\n",
        "                break\n",
        "            epoch += 1\n",
        "    print(\"Location #%d Optimization Finished in %d seconds!\" %(train_loc, time.time() - start))\n",
        "\n",
        "    # Test model\n",
        "\n",
        "    y_train_predicted = sess.run(pred,feed_dict)\n",
        "    y_test_predicted = sess.run(pred,validation_feed_dict)\n",
        "\n",
        "    show_eval(y_train_predicted[:,0],\n",
        "              y_train0[:,0],\n",
        "              y_test_predicted[:,0],\n",
        "              y_test0[:,0],\n",
        "              y_slope,y_bias,ann_name)\n",
        "    writeF90(os.path.join('/content/drive','My Drive',google_drive_dir,\"models\",abbrev_map[output_stations[0].lower()]),\n",
        "             abbrev_map[output_stations[0].lower()],\n",
        "             y_slope[0],y_bias[0],\n",
        "             sess.run(W1).transpose(),sess.run(b1),\n",
        "             sess.run(W2).transpose(),sess.run(b2),\n",
        "             sess.run(W3).transpose(),sess.run(b3))\n",
        "model_path = os.path.join('/content/drive','My Drive',google_drive_dir,\"models/%s/model.ckpt\" % (abbrev_map[output_stations[0].lower()]))\n",
        "save_path = saver.save(sess, model_path)\n",
        "print(\"Model saved in path: %s\" % save_path)\n",
        "with sess.as_default():\n",
        "    with sess.graph.as_default():\n",
        "        saved_test_loss = acc.eval(validation_feed_dict)\n",
        "        print(\"Train Error after LM:\", acc.eval({x: x_train_ori, y: y_train0}))\n",
        "        print(\"Test Error after LM:\", saved_test_loss)\n"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "epoch:   1 , mu: 5.00000e-02, train loss: 0.0015861286, val loss: 0.0044362084\n",
            "mu: 5.00000e-02, new loss: 0.00130, previous loss: 0.00159\n",
            "epoch:   2 , mu: 5.00000e-03, train loss: 0.0013031035, val loss: 0.0038177713\n",
            "mu: 5.00000e-03, new loss: 0.00089, previous loss: 0.00130\n",
            "mu: 5.00000e-02, new loss: 0.00065, previous loss: 0.00089\n",
            "epoch:   4 , mu: 5.00000e-03, train loss: 0.0006529613, val loss: 0.0038111105\n",
            "mu: 5.00000e-02, new loss: 0.00060, previous loss: 0.00065\n",
            "Location #3 Optimization Finished in 0 seconds!\n",
            "train mape:  0.1136\n",
            "train mse:  3273.34\n",
            "test mape:  0.2041\n",
            "test mse: 21213.82\n",
            "<class 'numpy.float32'>\n",
            "Model saved in path: /content/drive/My Drive/python_ANN/models/ORRSL/model.ckpt\n",
            "Train Error after LM: 0.00060221343\n",
            "Test Error after LM: 0.0039028123\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    }
  ]
}